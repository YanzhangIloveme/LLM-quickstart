{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b517113-143e-4c5b-b8b3-86c24485f12b",
   "metadata": {},
   "source": [
    "# GPTQ量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "450ba854-7cfb-4fb0-90aa-2b20842ced2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/opt/meituan/dolphinfs_zhangyan150/llm/transformers-tune/models\"\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"]= \"1\"\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee8e72a3-381e-4539-93b8-37b272f04f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/meituan/dolphinfs_zhangyan150/llm/transformers-tune/models\n"
     ]
    }
   ],
   "source": [
    "!echo $TRANSFORMERS_CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88f7e13f-3fe4-4736-8b52-98991d2a3209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里不量化6.7B了太大了，量化1.3B的模型 省钱嘻嘻\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GPTQConfig\n",
    "import torch\n",
    "\n",
    "quantization_config = GPTQConfig(\n",
    "     bits=4, # 量化精度\n",
    "     group_size=128,\n",
    "     dataset=[\"This is offline model\", \"Just some random dataset is here to quant\"],\n",
    "     desc_act=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "506b3371-906c-46c3-8a9c-f407e5d1e9d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-1.3b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9189f573-c3a4-482a-94b8-738bdd4ce0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantizing model.decoder.layers blocks :   0%|          | 0/24 [00:00<?, ?it/s]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:10<00:52, 10.58s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:11<00:20,  5.03s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:12<00:09,  3.27s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:14<00:04,  2.43s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:15<00:01,  1.96s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:19<00:00,  2.93s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :   4%|▍         | 1/24 [00:19<07:39, 19.98s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.17s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.16s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.13s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.13s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.13s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.34s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :   8%|▊         | 2/24 [00:30<05:15, 14.33s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.10s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.08s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.32s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  12%|█▎        | 3/24 [00:40<04:21, 12.46s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.15s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.13s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.10s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.33s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  17%|█▋        | 4/24 [00:50<03:52, 11.60s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.13s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.33s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  21%|██        | 5/24 [01:01<03:31, 11.13s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.13s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.10s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.09s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.30s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  25%|██▌       | 6/24 [01:11<03:14, 10.80s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.15s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.31s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  29%|██▉       | 7/24 [01:21<03:00, 10.61s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.10s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.10s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.36s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  33%|███▎      | 8/24 [01:31<02:48, 10.53s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.07s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.10s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.10s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.09s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.09s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.33s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  38%|███▊      | 9/24 [01:42<02:36, 10.43s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.09s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.09s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.09s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.10s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.32s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  42%|████▏     | 10/24 [01:52<02:24, 10.36s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.09s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.09s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.31s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  46%|████▌     | 11/24 [02:02<02:14, 10.31s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.10s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.10s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.33s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  50%|█████     | 12/24 [02:12<02:03, 10.29s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:08,  1.61s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:05,  1.33s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.25s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:05<00:02,  1.20s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:06<00:01,  1.19s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.39s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  54%|█████▍    | 13/24 [02:23<01:55, 10.49s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.09s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.10s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.13s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.36s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  58%|█████▊    | 14/24 [02:34<01:44, 10.45s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.10s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.34s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  62%|██████▎   | 15/24 [02:44<01:33, 10.40s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.10s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.13s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.13s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.13s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.14s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.40s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  67%|██████▋   | 16/24 [02:54<01:23, 10.44s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.13s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.35s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  71%|███████   | 17/24 [03:05<01:12, 10.42s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.14s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.14s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.13s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.39s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  75%|███████▌  | 18/24 [03:15<01:02, 10.44s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.14s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.14s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.16s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.16s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.37s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  79%|███████▉  | 19/24 [03:26<00:52, 10.46s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.14s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.16s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.36s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  83%|████████▎ | 20/24 [03:36<00:41, 10.45s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.08s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.10s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.09s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.09s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.10s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.35s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  88%|████████▊ | 21/24 [03:46<00:31, 10.39s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.13s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.15s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.15s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.37s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  92%|█████████▏| 22/24 [03:57<00:20, 10.41s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.14s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.11s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.13s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.13s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.36s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks :  96%|█████████▌| 23/24 [04:07<00:10, 10.40s/it]\n",
      "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  17%|█▋        | 1/6 [00:01<00:05,  1.14s/it]\u001b[A\n",
      "Quantizing layers inside the block:  33%|███▎      | 2/6 [00:02<00:04,  1.14s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|█████     | 3/6 [00:03<00:03,  1.14s/it]\u001b[A\n",
      "Quantizing layers inside the block:  67%|██████▋   | 4/6 [00:04<00:02,  1.13s/it]\u001b[A\n",
      "Quantizing layers inside the block:  83%|████████▎ | 5/6 [00:05<00:01,  1.14s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|██████████| 6/6 [00:10<00:00,  2.35s/it]\u001b[A\n",
      "Quantizing model.decoder.layers blocks : 100%|██████████| 24/24 [04:18<00:00, 10.76s/it]\n"
     ]
    }
   ],
   "source": [
    "quant_model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-1.3b\", \n",
    "                                                   quantization_config=quantization_config, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1213afae-e0e7-4728-9c1b-dc6464e7868b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict([('qweight',\n",
       "               tensor([[-1968072024, -1771280518,  1789289879,  ...,  1215579015,\n",
       "                         2053435976, -1754508700],\n",
       "                       [  967351451, -1785370714, -1778418564,  ...,  -878163915,\n",
       "                         -110706971,  2088397576],\n",
       "                       [  844485784, -1236563623,  -882554554,  ..., -1999525490,\n",
       "                        -1734957961,  2020046922],\n",
       "                       ...,\n",
       "                       [ 2072693399, -1532532076, -1689936233,  ..., -1186452839,\n",
       "                         1722255495, -1264216185],\n",
       "                       [-1516574263, -1742227464, -1234700615,  ..., -2004784949,\n",
       "                         1469679770,  1703914486],\n",
       "                       [ -674802553, -1164479124, -1505134731,  ..., -1685665369,\n",
       "                          -60266871,  -660960696]], device='cuda:0', dtype=torch.int32)),\n",
       "              ('qzeros',\n",
       "               tensor([[2004318071, 2004318071, 2004318071,  ..., 2004318071, 2004318071,\n",
       "                        2004318071],\n",
       "                       [2004318071, 2004318071, 2004318071,  ..., 2004318071, 2004318071,\n",
       "                        2004318071],\n",
       "                       [2004318071, 2004318071, 2004318071,  ..., 2004318071, 2004318071,\n",
       "                        2004318071],\n",
       "                       ...,\n",
       "                       [2004318071, 2004318071, 2004318071,  ..., 2004318071, 2004318071,\n",
       "                        2004318071],\n",
       "                       [2004318071, 2004318071, 2004318071,  ..., 2004318071, 2004318071,\n",
       "                        2004318071],\n",
       "                       [2004318071, 2004318071, 2004318071,  ..., 2004318071, 2004318071,\n",
       "                        2004318071]], device='cuda:0', dtype=torch.int32)),\n",
       "              ('scales',\n",
       "               tensor([[0.0029, 0.0037, 0.0039,  ..., 0.0035, 0.0028, 0.0038],\n",
       "                       [0.0034, 0.0039, 0.0039,  ..., 0.0051, 0.0028, 0.0048],\n",
       "                       [0.0040, 0.0030, 0.0041,  ..., 0.0050, 0.0044, 0.0035],\n",
       "                       ...,\n",
       "                       [0.0042, 0.0040, 0.0040,  ..., 0.0037, 0.0035, 0.0042],\n",
       "                       [0.0034, 0.0034, 0.0042,  ..., 0.0048, 0.0034, 0.0035],\n",
       "                       [0.0042, 0.0042, 0.0045,  ..., 0.0051, 0.0047, 0.0041]],\n",
       "                      device='cuda:0', dtype=torch.float16)),\n",
       "              ('g_idx',\n",
       "               tensor([ 0,  0,  0,  ..., 15, 15, 15], device='cuda:0', dtype=torch.int32)),\n",
       "              ('bias',\n",
       "               tensor([-0.0407, -0.0028, -0.0199,  ..., -0.0168, -0.0078, -0.0042],\n",
       "                      device='cuda:0', dtype=torch.float16))]),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict(),\n",
       " 'infeatures': 2048,\n",
       " 'outfeatures': 2048,\n",
       " 'bits': 4,\n",
       " 'group_size': 128,\n",
       " 'maxq': 15,\n",
       " 'half_indim': 1024,\n",
       " 'use_cuda_fp16': True,\n",
       " 'wf': tensor([[ 0,  4,  8, 12, 16, 20, 24, 28]], dtype=torch.int32),\n",
       " 'kernel_switch_threshold': 128,\n",
       " 'autogptq_cuda_available': False,\n",
       " 'autogptq_cuda': None,\n",
       " 'trainable': False,\n",
       " 'device': device(type='cuda', index=0)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检验准确性\n",
    "\n",
    "quant_model.model.decoder.layers[0].self_attn.q_proj.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6fe35b-9f92-4f52-bd53-0de48ef40118",
   "metadata": {},
   "source": [
    "# AWQ量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "573127e5-e748-4e04-95fc-81b71dbc7e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AwqConfig, AutoConfig\n",
    "from awq import AutoAWQForCausalLM\n",
    "\n",
    "model_path = \"facebook/opt-1.3b\"\n",
    "model = AutoAWQForCausalLM.from_pretrained(model_path, device_map=\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "quant_config = {\"zero_point\": True, \"q_group_size\": 128, \"w_bit\": 4, \"version\": \"GEMM\"}\n",
    "\n",
    "\n",
    "#  修改配置文件以使其与transformers集成兼容\n",
    "quantization_config = AwqConfig(\n",
    "    bits=quant_config[\"w_bit\"],\n",
    "    group_size=quant_config[\"q_group_size\"],\n",
    "    zero_point=quant_config[\"zero_point\"],\n",
    "    version=quant_config[\"version\"].lower(),\n",
    ").to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cfa903f-98ef-4308-b898-6d5ea2ea7c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quant_method': <QuantizationMethod.AWQ: 'awq'>,\n",
       " 'bits': 4,\n",
       " 'group_size': 128,\n",
       " 'zero_point': True,\n",
       " 'version': <AWQLinearVersion.GEMM: 'gemm'>,\n",
       " 'backend': <AwqBackendPackingMethod.AUTOAWQ: 'autoawq'>,\n",
       " 'fuse_max_seq_len': None,\n",
       " 'modules_to_fuse': None,\n",
       " 'do_fuse': False}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantization_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08795189-d3c8-43a1-ac69-a1e952b72e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.config.quantization_config = quantization_config\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
